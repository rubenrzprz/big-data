{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Streaming con Structured Streaming\n",
    "\n",
    "Structured Streaming emplea el motor de Spark SQL para el procesamiento de Streams.\n",
    "\n",
    "Comenzaremos creando el Spark Session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName(\"StructuredNetworkWordCountWindowed\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En una terminal de nuestra máquina, lanzamos el siguiente comando para envíar los mensajes por el puerto 9999:\n",
    "\n",
    "```nc -lk 9999```\n",
    "\n",
    "Creamos el DataFrame leyendo desde una conexión al localhost en el puerto 9999:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = (spark\n",
    "        .readStream\n",
    "        .format(\"socket\")\n",
    "        .option(\"host\", \"localhost\")\n",
    "        .option(\"port\", 9999)\n",
    "        .option(\"includeTimestamp\", \"true\")\n",
    "        .load())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "> Separar las líneas en palabras, transformarlas todas a minúscula y agrupar por palabra:\n",
    "\n",
    "- Obtenemos las palabras de las líneas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_ej1 = lines.select( \\\n",
    "        F.explode( \\\n",
    "            F.split(F.col(\"value\"), \" \")) \\\n",
    "        .alias(\"word\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Las transformamos en mínusuculas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowerWords_ej1 = words_ej1.withColumn(\"word\", F.lower(F.col(\"word\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Agrupamos por palabras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCounts_ej1 = lowerWords_ej1.groupBy(\"word\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lanzamos la query (los resultados se muestran por la consola donde lanzamos el notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ej1 = wordCounts_ej1 \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "query_ej1.awaitTermination(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "> Contar las palabras usando ventanas de tiempo.\n",
    "\n",
    "- Separamos las líneas por palabras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_ej2 = lines.select( \\\n",
    "        F.explode( \\\n",
    "            F.split(F.col(\"value\"), \" \")) \\\n",
    "        .alias(\"word\"),\n",
    "        F.col(\"timestamp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Agrupamos los datos por ventanas de 5 minutos y desplazamiento de 2 minutos y por palabras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowedCounts_ej2 = words_ej2 \\\n",
    "    .groupBy(F.window(F.col(\"timestamp\"), \"5 minutes\", \"2 minutes\"), F.col(\"word\")) \\\n",
    "    .count() \\\n",
    "    .orderBy('window')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lanzamos la query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "query_ej2 = windowedCounts_ej2 \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "query_ej2.awaitTermination(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "> Contar las palabras usando ventanas de tiempo y marcas de agua.\n",
    "\n",
    "- Separamos las líneas en palabras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_ej3 = lines.select(\n",
    "        F.explode(\n",
    "            F.split(F.col(\"value\"), \" \")) \\\n",
    "        .alias(\"word\"),\n",
    "        F.col(\"timestamp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Añadimos las marcas de agua con intervalo de 10 minutos, agrupamos los datos por ventanas de 10 minutos y desplazamiento de 5 minutos y contamos las palabras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowedCounts_ej3 = words_ej3 \\\n",
    "    .withWatermark(\"timestamp\", \"10 minutes\") \\\n",
    "    .groupBy(\n",
    "        F.window(F.col(\"timestamp\"), \"10 minutes\", \"5 minutes\"),\n",
    "        F.col(\"word\")) \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lanzamos la query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ej3 = windowedCounts_ej3 \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "query_ej3.awaitTermination(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "> Contar palabras consumiendo a través de un topic de Kafka.\n",
    "\n",
    "Para realizar este ejercicio, es necesario que el Kernel de Python de Jupyter cargue la dependencia de SparkSQL para Kafka. Para ello, editar el fichero kernel.json y añadir las siguientes dependencias a PYSPARK_SUBMIT_ARGS:\n",
    "```json\n",
    "\"--packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.3.0\"\n",
    "```\n",
    "- Leemos las líneas desde el topic *wordcount_topic* de Kafka (es necesario crearlo de antemano)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lines_ej4 = spark \\\n",
    "    .readStream\\\n",
    "    .format(\"kafka\")\\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\\\n",
    "    .option(\"subscribe\", \"wordcount_topic\")\\\n",
    "    .load()\\\n",
    "    .selectExpr(\"CAST(value AS STRING)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Separamos por palabras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_ej4 = lines_ej4.select(\n",
    "        F.explode(\n",
    "            F.split(F.col(\"value\"), \" \")) \\\n",
    "        .alias(\"word\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Agrupamos las palabras y las contamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wordCounts_ej4 = words_ej4.groupBy(\"word\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lanzamos la query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ej4 = wordCounts_ej4 \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "query_ej4.awaitTermination(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5\n",
    "> Listar los datos recibidos en formato JSON a través de un topic de Kafka.\n",
    "\n",
    "- Definimos el esquema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_ej5 = StructType() \\\n",
    "    .add(\"nombre\", StringType()) \\\n",
    "    .add(\"edad\", IntegerType()) \\\n",
    "    .add(\"peso\", FloatType()) \\\n",
    "    .add(\"direccion\", StringType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Leemos las líneas desde el topic *json_topic* de Kafka, convertimos la columna value a JSON y seleccionamos sus campos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_ej5 = spark\\\n",
    "        .readStream\\\n",
    "        .format(\"kafka\")\\\n",
    "        .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\\\n",
    "        .option(\"subscribe\", \"json_topic\")\\\n",
    "        .load()\\\n",
    "        .selectExpr(\"CAST(value AS STRING)\")\\\n",
    "        .select(F.from_json(F.col(\"value\"), schema).alias(\"parsed_value\"))\\\n",
    "        .select(\"parsed_value.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lanzamos la query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ej5 = lines_ej5.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "query_ej5.awaitTermination(60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
